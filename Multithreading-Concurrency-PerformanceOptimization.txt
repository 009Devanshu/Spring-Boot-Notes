====================================================
Motivation: Why we need threads?
====================================================
1. Responsiveness
2. Performance

Responsiveness with a single thread --
One user orders large on online store and it is taking too much time. Other users will have to wait for a long period of time.

1.Responsiveness
    Concurrency
    Can be achieved by multi-tasking between threads.
    Concurrency=Multitasking
    task1 task2 task1 task2 task1 task2
    Note: We don't need multiple cores to achieve Concurrency.

2.Performance
    We can create an illusion of multiple tasks executing in parallel using just a single core.
    With multiple cores, we can truly run taks completely in parallel.
    Ex 
        Core 2: task3 task4 task3 task4 task3 
        Core 1: task1 task2 task1 task2 task1 task2 


What threads are and where they live --
When we turn on the computer. Operating system from disk/hard drive loaded into the memory. Operating system provies an interaction between hardware and cpu. So, we can 
focus on developing our apps. All our applications reside on the disc in the form of a file. When user runs the application, the Operating system takes the program from the 
disc and creates instance of that application in the memory. That instance is called a process and it is sometimes called context of an application. Each process is completely 
isolated from any other process that runs on the system. Process contains metadata like process id, files for reading and writing, the code containing instructions that 
are to be executed on the cpu, heap that contains all the data that cpu needs and atleast one thread that is main thread. 
A thread contains two main things--
>The stack.
>The instruction pointer.    
In a multithreaded application, each thread comes with its own stack and its own instruction pointer. 

Stack - Region in memory where local variables are stored and passed into functions.
Instruction pointer - Address of the next instruction that the thread is going to execute.





*********************************************************************************************************************************
Operating Systems Fundamentals - Part 2
*********************************************************************************************************************************
What We learn in this lecture --
Context Switch
Thread Scheduling
Threads vs Processes


Each instance of an application that we run runs independently from other processes. Normally there are way more processes that cores. Each process has one or more threads and 
all these threads are competiting with each other to be executed on cpu. Even if we have multiple cores, there are way more threads than cores. So the operating system 
will have to run one thread, then stop it and run another thread and so on. 

Context Switch
1> Stop thread 1
2> Schedule thread 1 out
3> Schedule thread 2 in 
4> Start thread 2
This is context Switch.

Context Switching between threads from different processes is costly. Too many threads causes thrashing (speding more time in management than real productive work). The reason 
is that each thread consumes resources in the cpu and memory. When we Switch from one thread to a different thread--
    > Store data for one thread 
    > Restore data for another thread. 

Context Switching between threads from same process is cheaper than context Switch between different processes. The reason is that threads inside a process share a lot of resources 
themselves.




Now, let's see how operating system decides when to run which thread and when to perform context Switch.
Let's we have four threads (length order decreasing)
Music Player ui (3)
Music Player (2)
Text Editor UI (4)
File Saver (1)



Suppose cpu is  Scheduling threads on the basis of first come first serve
Problem: Long thread(suppose file saver is long thread) can cause starvation for other thread.
May cause UI threads being unresponsive - Bad User Experience

Suppose cpu is Scheduling threads on the basis of shortest job first
This has also a Problem. There are user related events coming to our system all the time, so we keep Scheduling shortest job first all the time, the longer tasks that 
involves computation will never be executed. 

Now, we understand the tradeoffs and challenges with Scheduling threads. Let's learn how it really works in most operating systems. In general operating system divides 
the time into moderately sized pieces called epochs. In each epoch, the operating system allocates a different time slice for each thread. Not all the threads get to run or 
complete in each epoch. The decision on how to allocate the time for each thread is based on the dynamic priority the operating system maintains for each thread.

Dynamic priority  = Static priority + bonus
    (bonus can be negative)

Static priority is set by the developer programmatically
Bonus is adjusted by the operating system in every epoch for each thread. 

Using dynamic priority, the OS will give preference for Interactive threads (such as User Interface threads)
OS will give preference to threads that did not complete in the last epoch or did not get enough time to run - preventing starvation.



When to prefer multithreaded architecture 
> Prefer if the tasks share a lot of data.
> switching between threads of the same process is faster (shorter context switching)

When to prefer multiprocess architecture
> Security and stability is of higher priority. (Suppose one thread bring down the entire app)
> Tasks are unrelated to each other. 



*******************************************************************
Section 2: Threading Fundamentals - Thread Creation
Thread Creation - Part 1, Thread Capabilities & Debugging
*******************************************************************
Lecture Agenda
-------------------
Thread Creation with java.lang.Runnable
Thread class capabilities 
Thread Debugging























